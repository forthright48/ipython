{
 "metadata": {
  "name": "",
  "signature": "sha256:f4b3095364242cc24bf640ef9519193c460198439092d68dd99326498f659e34"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Wuxiaworld Web Scrapper - Turn Translated Chinese Novel to PDF\n",
      "\n",
      "I tend to read lots of translated chinese novel from this site. But it requires internet connection, as each chapter is a HTML page. I want to scrap the chapters from the website and convert to pdf, so that I can read them offline\n",
      "\n",
      "## How am I going to do it?\n",
      "\n",
      "I am planning to use 'requests' and 'beautifulsoup4' to write a python webscrapper"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests as rq # To get html of webpage as string\n",
      "from bs4 import BeautifulSoup as bs # To parse HTML string into a DOM\n",
      "from IPython.core.display import display, HTML # For pretty HTML output in ipython\n",
      "from urllib.parse import urlparse # For easy parsing of url"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = \"http://www.wuxiaworld.com/\" # Url of the website I am going to scrap\n",
      "r = rq.get(url)\n",
      "display ( r.status_code, r.encoding, r.url )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "200"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "'UTF-8'"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "'http://www.wuxiaworld.com/'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "soup = bs(r.text, \"lxml\")\n",
      "title = soup.title\n",
      "display ( title.text )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "'Wuxiaworld \u2013 Chinese fantasy novels and light novels!'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Grab all links in navbar and remove anchor links\n",
      "aLink = [ ( link.attrs[\"href\"], link.text ) for link in soup.select('nav a') if link.attrs[\"href\"].startswith(\"#\") == False]\n",
      "\n",
      "# Links towards the end are not related to chinese novels, so slice them up\n",
      "novelList = [ ( urlparse(link).path, name ) for ( link, name ) in aLink ][1:-15]\n",
      "\n",
      "display ( list ( enumerate ( novelList ) ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "[(0, ('/7-killers/', '7 Killers (\u4e03\u6740\u624b)')),\n",
        " (1, ('/col-index/', 'Child of Light (\u5149\u4e4b\u5b50)')),\n",
        " (2, ('/cdindex-html/', 'Coiling Dragon (\u76d8\u9f99)')),\n",
        " (3, ('/dkwss/', 'Dragon King With Seven Stars (\u4e03\u661f\u9f99\u738b)')),\n",
        " (4, ('/hsnt-index/', 'Heroes Shed No Tears (\u82f1\u96c4\u4e0d\u6d41\u6cea)')),\n",
        " (5, ('/tymyd-index/', 'Horizon, Bright Moon, Sabre (\u5929\u6daf\u660e\u6708\u5200)')),\n",
        " (6, ('/st-index/', 'Stellar Transformations (\u661f\u8fb0\u53d8)')),\n",
        " (7, ('/absolute-choice-index/', 'Absolute Choice (\u7edd\u5bf9\u9009\u9879)')),\n",
        " (8, ('/atg-index/', 'Against the Gods (\u9006\u5929\u90aa\u795e)')),\n",
        " (9, ('/awe-index/', 'A Will Eternal (\u4e00\u5ff5\u6c38\u6052)')),\n",
        " (10, ('/btth-index/', 'Battle Through the Heavens (\u6597\u7834\u82cd\u7a79)')),\n",
        " (11, ('/desolate-era-index/', 'Desolate Era (\u83bd\u8352\u7eaa)')),\n",
        " (12, ('/emperor-index/', 'Emperor\u2019s Domination (\u5e1d\u9738)')),\n",
        " (13, ('/gor-index/', 'Gate of Revelation (\u5929\u542f\u4e4b\u95e8)')),\n",
        " (14, ('/hjc-index/', 'Heavenly Jewel Change (\u5929\u73e0\u53d8)')),\n",
        " (15, ('/issth-index/', 'I Shall Seal the Heavens (\u6211\u6b32\u5c01\u5929)')),\n",
        " (16, ('/ldk-index/', 'Legend of the Dragon King (\u9f99\u738b\u4f20\u8bf4)')),\n",
        " (17, ('/mga-index/', 'Martial God Asura (\u4fee\u7f57\u6b66\u795e)')),\n",
        " (18, ('/pw-index/', 'Perfect World (\u5b8c\u7f8e\u4e16\u754c)')),\n",
        " (19, ('/rebirth-index/', 'Rebirth of the Thief')),\n",
        " (20, ('/renegade-index/', 'Renegade Immortal (\u4ed9\u9006)')),\n",
        " (21, ('/sfl-index/', 'Skyfire Avenue (\u5929\u706b\u5927\u9053)')),\n",
        " (22, ('/sotr-index/', 'Sovereign of the Three Realms (\u4e09\u754c\u72ec\u5c0a)')),\n",
        " (23, ('/sr-index/', 'Spirit Realm (\u7075\u57df)')),\n",
        " (24, ('/tdg-index/', 'Tales of Demons & Gods (\u5996\u795e\u8bb0)')),\n",
        " (25, ('/ti-index/', 'Terror Infinity (\u65e0\u9650\u6050\u6016)')),\n",
        " (26, ('/tgr-index/', 'The Great Ruler (\u5927\u4e3b\u5bb0)')),\n",
        " (27, ('/usaw-index/', 'Upgrade Specialist in Another World')),\n",
        " (28, ('/wmw-index/', 'Warlock of the Magus World (\u5deb\u754c\u672f\u58eb)')),\n",
        " (29, ('/wdqk-index/', 'Wu Dong Qian Kun (\u6b66\u52a8\u4e7e\u5764)'))]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have a novelList, let's try to process just one of the novel. If we can scrap one novel, we can scrap them all.\n",
      "\n",
      "## Scraping A Single Novel\n",
      "\n",
      "Each novel will have a seperate folder, with folders having name in `<url-nick>-<name>` format.\n",
      "\n",
      "Inside the folder, we will have a info.html file that will have it's info page in it.\n",
      "\n",
      "Next we will have a file info.clean.html, that will have the same page, but with unnecessary tags removed, like comments and ads.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}